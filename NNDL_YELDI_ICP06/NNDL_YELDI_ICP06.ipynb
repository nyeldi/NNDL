{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In class programming:\n",
        "1. Save the model and use the saved model to predict on new text data (ex, “A lot of good things are happening.\n",
        "We are respected again throughout the world, and that's a great thing.@realDonaldTrump”)\n"
      ],
      "metadata": {
        "id": "xdo2k5bzH6um"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P69JPguGkKT",
        "outputId": "ae011e13-4826-4b7e-a06b-04c47cc81e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 - 48s - loss: 0.8251 - accuracy: 0.6460 - 48s/epoch - 166ms/step\n",
            "144/144 - 4s - loss: 0.7640 - accuracy: 0.6732 - 4s/epoch - 30ms/step\n",
            "0.7640113830566406\n",
            "0.6732197403907776\n",
            "['loss', 'accuracy']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import re\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = pd.read_csv('/content/Sentiment (3) (2).csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n",
        "\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "X = pad_sequences(X)\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "def createmodel():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "    return model\n",
        "# print(model.summary())\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "batch_size = 32\n",
        "model = createmodel()\n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2)\n",
        "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"sentiment_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agqu6PWtHK9r",
        "outputId": "7756b112-9f61-4aef-d382-8d757fe6706b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model(\"/content/sentiment_model.h5\")\n",
        "\n",
        "# Define a function for preprocessing text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Example new text data\n",
        "new_text = \"A lot of good things are happening. We are respected again throughout the world, and that's a great thing. @realDonaldTrump\"\n",
        "\n",
        "# Preprocess the new text data\n",
        "new_text = preprocess_text(new_text)\n",
        "\n",
        "# Tokenize and pad the new text data\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts([new_text])\n",
        "X_new = tokenizer.texts_to_sequences([new_text])\n",
        "X_new = pad_sequences(X_new, maxlen=model.input_shape[1])\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Determine the sentiment based on the prediction\n",
        "sentiments = ['Negative', 'Neutral', 'Positive']\n",
        "predicted_sentiment = sentiments[predictions.argmax()]\n",
        "\n",
        "# Print the result\n",
        "print(\"Predicted Sentiment: \" + predicted_sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NmsF_0aHbPF",
        "outputId": "d913ef4d-75ec-496b-f40d-b1b1c8f4f443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 278ms/step\n",
            "Predicted Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-lgAOGUHyQz",
        "outputId": "1ac22ee4-4dd7-4124-a415-1512734d7ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Apply GridSearchCV on the source code provided in the class."
      ],
      "metadata": {
        "id": "vhyzbgeXIYSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "vMahtCMzIZ3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Assuming the data loading and preprocessing steps are the same\n",
        "\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "# Assuming tokenizer fitting and text preprocessing is done here\n",
        "\n",
        "# Sample data (replace with your actual data loading and preprocessing)\n",
        "texts = [\"This is a positive sentence.\", \"This is a negative sentence.\", \"Another positive one.\", \"And a negative one.\"] # Added more data\n",
        "labels = [1, 0, 1, 0]  # 1 for positive, 0 for negative\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=10)  # Adjust maxlen as needed\n",
        "Y = to_categorical(labels, num_classes=2)  # Adjust num_classes as needed\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "def createmodel(optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(2, activation='softmax'))  # Fixed number of units to match number of classes\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    # Build the model here\n",
        "    model.build(input_shape=(None, X.shape[1])) # Building the model to define the outputs\n",
        "    return model\n",
        "\n",
        "# Define the KerasClassifier with the build_fn as our model creation function\n",
        "model = KerasClassifier(model=createmodel, verbose=2)\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'batch_size': [32, 64],\n",
        "    'epochs': [1, 2],\n",
        "    'optimizer': ['adam', 'rmsprop']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
        "# Fit GridSearchCV\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TjOrFJ9IjNy",
        "outputId": "3a48aff7-24aa-42fa-ea96-7dac1d40d2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 4s - 4s/step - accuracy: 0.5000 - loss: 0.6899\n",
            "1/1 - 0s - 228ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.0000e+00 - loss: 0.7061\n",
            "1/1 - 0s - 190ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6895\n",
            "1/1 - 0s - 331ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 0.0000e+00 - loss: 0.7216\n",
            "1/1 - 0s - 195ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7b8ec33a5b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 1.0000 - loss: 0.6759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b8ec28f1900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 214ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x7b8ec26b0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 0.5000 - loss: 0.7035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b8ec1a9caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 191ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1/1 - 3s - 3s/step - accuracy: 0.0000e+00 - loss: 0.7102\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 144ms/step - accuracy: 1.0000 - loss: 0.6424\n",
            "1/1 - 0s - 311ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 1.0000 - loss: 0.6789\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 37ms/step - accuracy: 0.5000 - loss: 0.6872\n",
            "1/1 - 0s - 206ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 0.5000 - loss: 0.6964\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 57ms/step - accuracy: 0.5000 - loss: 0.6961\n",
            "1/1 - 0s - 210ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 1.0000 - loss: 0.6610\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 63ms/step - accuracy: 1.0000 - loss: 0.5919\n",
            "1/1 - 0s - 204ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 133ms/step - accuracy: 0.5000 - loss: 0.6956\n",
            "1/1 - 0s - 325ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6939\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 58ms/step - accuracy: 0.5000 - loss: 0.7021\n",
            "1/1 - 0s - 220ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 1.0000 - loss: 0.6585\n",
            "1/1 - 0s - 219ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 0.5000 - loss: 0.6840\n",
            "1/1 - 0s - 189ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6923\n",
            "1/1 - 0s - 198ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 1.0000 - loss: 0.6502\n",
            "1/1 - 0s - 324ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 0.0000e+00 - loss: 0.6996\n",
            "1/1 - 0s - 199ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 0.5000 - loss: 0.6803\n",
            "1/1 - 0s - 201ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 0.0000e+00 - loss: 0.7320\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 60ms/step - accuracy: 1.0000 - loss: 0.6434\n",
            "1/1 - 1s - 758ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6861\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 136ms/step - accuracy: 0.0000e+00 - loss: 0.7026\n",
            "1/1 - 0s - 286ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6937\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 60ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "1/1 - 0s - 201ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 1.0000 - loss: 0.6845\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.5929\n",
            "1/1 - 0s - 203ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 2s - 2s/step - accuracy: 1.0000 - loss: 0.6908\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 38ms/step - accuracy: 0.5000 - loss: 0.6890\n",
            "1/1 - 0s - 218ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.5000 - loss: 0.6876\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 37ms/step - accuracy: 0.5000 - loss: 0.6904\n",
            "1/1 - 0s - 203ms/step\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 3s - 3s/step - accuracy: 0.0000e+00 - loss: 0.7087\n",
            "Epoch 2/2\n",
            "1/1 - 0s - 73ms/step - accuracy: 0.6667 - loss: 0.6630\n",
            "Best: 0.666667 using {'batch_size': 32, 'epochs': 2, 'optimizer': 'adam'}\n"
          ]
        }
      ]
    }
  ]
}